# åŸºäºæ‰©æ•£ä¼˜åŒ–çš„åŒ»å­¦å›¾åƒæ™ºèƒ½åˆ†å‰²ç³»ç»Ÿè®¾è®¡ä¸å®ç°

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå…ˆè¿›çš„åŒ»å­¦å›¾åƒæ™ºèƒ½åˆ†å‰²ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿç»“åˆäº†æ·±åº¦å­¦ä¹ åˆ†å‰²æ¨¡å‹ä¸æ‰©æ•£æ¨¡å‹ï¼Œèƒ½å¤Ÿå¯¹åŒ»å­¦å›¾åƒä¸­çš„ç›®æ ‡åŒºåŸŸè¿›è¡Œé«˜ç²¾åº¦è‡ªåŠ¨åˆ†å‰²ï¼Œå¹¶é€šè¿‡æ‰©æ•£å»å™ªæœºåˆ¶è¿›ä¸€æ­¥ä¼˜åŒ–åˆ†å‰²è¾¹ç•Œè´¨é‡ã€‚ç³»ç»Ÿé‡‡ç”¨ä¸¤é˜¶æ®µåˆ†å‰²ç­–ç•¥ï¼šé¦–å…ˆä½¿ç”¨CPUNetè¿›è¡Œç²—åˆ†å‰²ï¼Œç„¶åä½¿ç”¨æ‰©æ•£æ¨¡å‹è¿›è¡Œè¾¹ç•Œç²¾ç»†åŒ–ï¼Œä»è€Œå®ç°é«˜è´¨é‡çš„åŒ»å­¦å›¾åƒåˆ†å‰²ã€‚

---

## 5.1 éœ€æ±‚åˆ†æ

### 5.1.1 ä¸šåŠ¡éœ€æ±‚åˆ†æ

#### 1. èƒŒæ™¯ä¸åŠ¨æœº

åŒ»å­¦å›¾åƒåˆ†å‰²æ˜¯è®¡ç®—æœºè¾…åŠ©è¯Šæ–­ï¼ˆCADï¼‰ç³»ç»Ÿä¸­çš„æ ¸å¿ƒæŠ€æœ¯ä¹‹ä¸€ï¼Œå¯¹äºç–¾ç—…çš„æ—©æœŸå‘ç°ã€æ²»ç–—æ–¹æ¡ˆåˆ¶å®šå’Œæ‰‹æœ¯è§„åˆ’å…·æœ‰é‡è¦æ„ä¹‰ã€‚ä¼ ç»Ÿçš„æ‰‹å·¥åˆ†å‰²æ–¹æ³•è€—æ—¶è´¹åŠ›ä¸”ä¸»è§‚æ€§å¼ºï¼Œéš¾ä»¥æ»¡è¶³ç°ä»£åŒ»ç–—å¯¹æ•ˆç‡å’Œå‡†ç¡®æ€§çš„è¦æ±‚ã€‚å› æ­¤ï¼Œå¼€å‘ä¸€ä¸ªè‡ªåŠ¨åŒ–ã€æ™ºèƒ½åŒ–çš„åŒ»å­¦å›¾åƒåˆ†å‰²ç³»ç»Ÿå…·æœ‰é‡è¦çš„ä¸´åºŠåº”ç”¨ä»·å€¼ã€‚

#### 2. ä¸šåŠ¡ç›®æ ‡

- **æé«˜è¯Šæ–­æ•ˆç‡**ï¼šé€šè¿‡è‡ªåŠ¨åŒ–åˆ†å‰²æŠ€æœ¯ï¼Œå¤§å¹…å‡å°‘åŒ»ç”Ÿæ‰‹å·¥å‹¾ç”»ç—…ç¶åŒºåŸŸçš„æ—¶é—´ï¼Œä»è€Œæé«˜è¯Šæ–­æ•ˆç‡
- **æå‡åˆ†å‰²ç²¾åº¦**ï¼šåˆ©ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œå®ç°å¯¹åŒ»å­¦å›¾åƒä¸­ç›®æ ‡åŒºåŸŸçš„ç²¾ç¡®åˆ†å‰²ï¼Œç‰¹åˆ«æ˜¯è¾¹ç•Œç»†èŠ‚çš„å‡†ç¡®è¯†åˆ«
- **é™ä½ä¸»è§‚è¯¯å·®**ï¼šé‡‡ç”¨æ ‡å‡†åŒ–çš„è‡ªåŠ¨åˆ†å‰²ç®—æ³•ï¼Œå‡å°‘äººå·¥åˆ†å‰²å¸¦æ¥çš„ä¸»è§‚æ€§å’Œä¸ä¸€è‡´æ€§
- **æ”¯æŒå¤šæ¨¡æ€åŒ»å­¦å›¾åƒ**ï¼šç³»ç»Ÿéœ€è¦æ”¯æŒCTã€å†…çª¥é•œã€Xå…‰ç­‰å¤šç§åŒ»å­¦å½±åƒæ¨¡æ€
- **æ˜“äºé›†æˆä¸éƒ¨ç½²**ï¼šæä¾›å‹å¥½çš„ç”¨æˆ·ç•Œé¢å’ŒAPIæ¥å£ï¼Œä¾¿äºä¸ç°æœ‰åŒ»ç–—ä¿¡æ¯ç³»ç»Ÿé›†æˆ

#### 3. åº”ç”¨åœºæ™¯

- **è‚¿ç˜¤æ£€æµ‹ä¸åˆ†å‰²**ï¼šåœ¨CTæˆ–MRIå›¾åƒä¸­è‡ªåŠ¨è¯†åˆ«å¹¶åˆ†å‰²è‚¿ç˜¤åŒºåŸŸ
- **å™¨å®˜åˆ†å‰²**ï¼šå¯¹å¿ƒè„ã€è‚ºã€è‚è„ç­‰å™¨å®˜è¿›è¡Œè‡ªåŠ¨åˆ†å‰²ï¼Œè¾…åŠ©æ‰‹æœ¯è§„åˆ’
- **ç—…å˜åŒºåŸŸå®šä½**ï¼šåœ¨å†…çª¥é•œæˆ–Xå…‰å›¾åƒä¸­è‡ªåŠ¨æ ‡æ³¨ç—…å˜ä½ç½®
- **æœ¯å‰è§„åˆ’**ï¼šä¸ºå¤–ç§‘æ‰‹æœ¯æä¾›ç²¾ç¡®çš„ä¸‰ç»´è§£å‰–ç»“æ„åˆ†å‰²
- **ç–—æ•ˆè¯„ä¼°**ï¼šé€šè¿‡è¿ç»­å½±åƒå¯¹æ¯”ï¼Œè¯„ä¼°æ²»ç–—æ•ˆæœ

#### 4. ç”¨æˆ·éœ€æ±‚

- **åŒ»ç”Ÿç”¨æˆ·**ï¼šéœ€è¦å¿«é€Ÿã€å‡†ç¡®çš„åˆ†å‰²ç»“æœï¼Œç•Œé¢ç®€æ´æ˜“ç”¨ï¼Œèƒ½å¤Ÿå¤„ç†å•å¼ æˆ–æ‰¹é‡å›¾åƒ
- **ç ”ç©¶äººå‘˜**ï¼šéœ€è¦çµæ´»çš„é…ç½®é€‰é¡¹ï¼Œèƒ½å¤Ÿè°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œè·å–ä¸­é—´ç»“æœç”¨äºåˆ†æ
- **ç³»ç»Ÿç®¡ç†å‘˜**ï¼šéœ€è¦ç¨³å®šçš„ç³»ç»Ÿæ€§èƒ½ï¼Œæ˜“äºéƒ¨ç½²å’Œç»´æŠ¤ï¼Œæ”¯æŒå¤šç”¨æˆ·å¹¶å‘è®¿é—®

#### 5. ä¸šåŠ¡çº¦æŸ

- **å‡†ç¡®æ€§è¦æ±‚**ï¼šåˆ†å‰²ç»“æœéœ€è¦è¾¾åˆ°ä¸´åºŠåº”ç”¨æ ‡å‡†ï¼Œç‰¹åˆ«æ˜¯è¾¹ç•Œç²¾åº¦
- **å¤„ç†é€Ÿåº¦**ï¼šå•å¼ å›¾åƒå¤„ç†æ—¶é—´åº”æ§åˆ¶åœ¨åˆç†èŒƒå›´å†…ï¼ˆé€šå¸¸<10ç§’ï¼‰
- **æ•°æ®å®‰å…¨**ï¼šç¬¦åˆåŒ»ç–—æ•°æ®éšç§ä¿æŠ¤ç›¸å…³æ³•è§„ï¼ˆå¦‚HIPAAã€GDPRï¼‰
- **å…¼å®¹æ€§**ï¼šæ”¯æŒå¸¸è§çš„åŒ»å­¦å›¾åƒæ ¼å¼ï¼ˆDICOMã€NIfTIç­‰ï¼‰
- **å¯æ‰©å±•æ€§**ï¼šç³»ç»Ÿæ¶æ„åº”æ”¯æŒæœªæ¥åŠŸèƒ½æ‰©å±•å’Œæ¨¡å‹æ›´æ–°

### 5.1.2 åŠŸèƒ½éœ€æ±‚åˆ†æ

#### 1. å›¾åƒé¢„å¤„ç†åŠŸèƒ½

**FR-1.1 å¤šæ ¼å¼å›¾åƒåŠ è½½**
- æ”¯æŒæ ‡å‡†åŒ»å­¦å›¾åƒæ ¼å¼ï¼šDICOM (.dcm)ã€NIfTI (.nii, .nii.gz)
- æ”¯æŒå¸¸è§å›¾åƒæ ¼å¼ï¼šPNGã€JPEGã€BMPã€TIFF
- è‡ªåŠ¨è¯†åˆ«å›¾åƒæ ¼å¼å¹¶è¿›è¡Œç›¸åº”è§£ç 

**FR-1.2 å›¾åƒæ ‡å‡†åŒ–å¤„ç†**
- å¼ºåº¦å½’ä¸€åŒ–ï¼šæ”¯æŒMinMaxå½’ä¸€åŒ–ã€Z-scoreå½’ä¸€åŒ–
- å¯¹æ¯”åº¦å¢å¼ºï¼šåŸºäºCLAHEï¼ˆå¯¹æ¯”åº¦å—é™è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼‰çš„å¯¹æ¯”åº¦å¢å¼º
- é™å™ªå¤„ç†ï¼šé«˜æ–¯æ»¤æ³¢ã€ä¸­å€¼æ»¤æ³¢ç­‰é™å™ªæ–¹æ³•
- å°ºå¯¸è°ƒæ•´ï¼šè‡ªåŠ¨å°†è¾“å…¥å›¾åƒè°ƒæ•´åˆ°æ¨¡å‹æ‰€éœ€å°ºå¯¸ï¼ˆ256Ã—256ï¼‰

**FR-1.3 æ•°æ®å¢å¼ºï¼ˆè®­ç»ƒé˜¶æ®µï¼‰**
- å‡ ä½•å˜æ¢ï¼šæ—‹è½¬ã€ç¿»è½¬ã€ç¼©æ”¾ã€å¹³ç§»
- äº®åº¦å’Œå¯¹æ¯”åº¦è°ƒæ•´
- éšæœºå™ªå£°æ·»åŠ 
- å¼¹æ€§å½¢å˜

#### 2. æ™ºèƒ½åˆ†å‰²åŠŸèƒ½

**FR-2.1 ç²—åˆ†å‰²æ¨¡å—ï¼ˆCPUNetï¼‰**
- åŸºäºU-Netæ¶æ„çš„ç¼–ç å™¨-è§£ç å™¨ç½‘ç»œ
- æ³¨æ„åŠ›æœºåˆ¶å¢å¼ºç‰¹å¾æå–
- å¤šå°ºåº¦ç‰¹å¾èåˆ
- è¾“å‡ºäºŒå€¼åŒ–åˆ†å‰²æ©ç ï¼ˆæ¦‚ç‡å›¾ï¼‰

**FR-2.2 æ‰©æ•£ä¼˜åŒ–æ¨¡å—**
- åŸºäºå»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆDDPMï¼‰çš„è¾¹ç•Œç»†åŒ–
- ä»¥åŸå§‹å›¾åƒä¸ºæ¡ä»¶çš„è¿­ä»£å»å™ªè¿‡ç¨‹
- å¯é…ç½®çš„æ¨ç†æ­¥æ•°ï¼ˆé»˜è®¤20æ­¥ï¼‰
- å™ªå£°æ°´å¹³è‡ªé€‚åº”è°ƒæ•´

**FR-2.3 åˆ†å‰²æ¨¡å¼é€‰æ‹©**
- ä»…ç²—åˆ†å‰²æ¨¡å¼ï¼šä»…ä½¿ç”¨CPUNetå¿«é€Ÿåˆ†å‰²
- ç²¾ç»†åˆ†å‰²æ¨¡å¼ï¼šå¯ç”¨æ‰©æ•£ä¼˜åŒ–è·å¾—æ›´é«˜è´¨é‡è¾¹ç•Œ
- ç”¨æˆ·å¯æ ¹æ®éœ€æ±‚åŠ¨æ€åˆ‡æ¢

#### 3. åå¤„ç†åŠŸèƒ½

**FR-3.1 å½¢æ€å­¦æ“ä½œ**
- å¼€è¿ç®—ï¼šå»é™¤å°çš„å™ªå£°ç‚¹
- é—­è¿ç®—ï¼šå¡«å……å°çš„ç©ºæ´
- è†¨èƒ€å’Œè…èš€ï¼šè°ƒæ•´åˆ†å‰²è¾¹ç•Œ

**FR-3.2 åŒºåŸŸä¼˜åŒ–**
- è¿é€šåŸŸåˆ†æï¼šè¯†åˆ«å¹¶æ ‡è®°ç‹¬ç«‹çš„åˆ†å‰²åŒºåŸŸ
- å°å¯¹è±¡ç§»é™¤ï¼šè¿‡æ»¤é¢ç§¯å°äºé˜ˆå€¼çš„åŒºåŸŸ
- å­”æ´å¡«å……ï¼šå¡«å……åˆ†å‰²åŒºåŸŸå†…çš„ç©ºæ´
- è¾¹ç•Œå¹³æ»‘ï¼šé€šè¿‡å¤šè¾¹å½¢è¿‘ä¼¼å¹³æ»‘è¾¹ç•Œæ›²çº¿

**FR-3.3 è´¨é‡è¯„ä¼°**
- åˆ†å‰²åŒºåŸŸé¢ç§¯ç»Ÿè®¡
- åˆ†å‰²è´¨é‡æŒ‡æ ‡è®¡ç®—ï¼ˆè‹¥æœ‰çœŸå€¼ï¼‰ï¼šDiceç³»æ•°ã€IoUã€ç²¾ç¡®ç‡ã€å¬å›ç‡
- åˆ†å‰²ç½®ä¿¡åº¦è¯„ä¼°

#### 4. å¯è§†åŒ–åŠŸèƒ½

**FR-4.1 ç»“æœå±•ç¤º**
- åŸå§‹å›¾åƒæ˜¾ç¤º
- åˆ†å‰²æ©ç å åŠ æ˜¾ç¤ºï¼ˆå¯è°ƒé€æ˜åº¦ï¼‰
- è½®å»“çº¿ç»˜åˆ¶ï¼ˆç²—åˆ†å‰²å’Œç²¾åˆ†å‰²å¯¹æ¯”ï¼‰
- å¯¹æ¯”è§†å›¾ï¼šå¹¶æ’æ˜¾ç¤ºå¤„ç†å‰åç»“æœ

**FR-4.2 äº¤äº’å¼ç•Œé¢**
- åŸºäºGradioçš„Webç•Œé¢
- æ‹–æ‹½ä¸Šä¼ å›¾åƒ
- å®æ—¶å‚æ•°è°ƒæ•´ï¼ˆé€æ˜åº¦ã€æ‰©æ•£æ­¥æ•°ç­‰ï¼‰
- ç»“æœä¸‹è½½åŠŸèƒ½

**FR-4.3 æ‰¹é‡å¤„ç†å¯è§†åŒ–**
- å›¾åº“å±•ç¤ºæ‰¹é‡å¤„ç†ç»“æœ
- ç»Ÿè®¡ä¿¡æ¯æ±‡æ€»
- æ‰¹é‡ç»“æœå¯¼å‡º

#### 5. æ¨¡å‹è®­ç»ƒåŠŸèƒ½

**FR-5.1 è®­ç»ƒæµç¨‹ç®¡ç†**
- CPUNetå•ç‹¬è®­ç»ƒ
- æ‰©æ•£æ¨¡å‹å•ç‹¬è®­ç»ƒ
- è”åˆè®­ç»ƒæ¨¡å¼
- è®­ç»ƒè¿‡ç¨‹ç›‘æ§ï¼ˆæŸå¤±æ›²çº¿ã€éªŒè¯æŒ‡æ ‡ï¼‰

**FR-5.2 æ•°æ®ç®¡ç†**
- è‡ªåŠ¨æ•°æ®é›†åŠ è½½
- è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†åˆ’åˆ†
- æ•°æ®å¢å¼ºpipelineé…ç½®

**FR-5.3 æ¨¡å‹ç®¡ç†**
- æ£€æŸ¥ç‚¹ä¿å­˜å’ŒåŠ è½½
- æœ€ä½³æ¨¡å‹è‡ªåŠ¨ä¿å­˜
- æ¨¡å‹ç‰ˆæœ¬ç®¡ç†
- é¢„è®­ç»ƒæ¨¡å‹åŠ è½½

#### 6. APIæ¥å£åŠŸèƒ½

**FR-6.1 Python API**
- `SegmentationPipeline` ç±»å°è£…å®Œæ•´æµç¨‹
- å•å¼ å›¾åƒåˆ†å‰²æ¥å£
- æ‰¹é‡å›¾åƒåˆ†å‰²æ¥å£
- ä¸­é—´ç»“æœè·å–æ¥å£

**FR-6.2 Web API**
- RESTful APIæ¥å£ï¼ˆå¯æ‰©å±•ï¼‰
- å›¾åƒä¸Šä¼ å’Œå¤„ç†
- ç»“æœæŸ¥è¯¢å’Œä¸‹è½½
- æ‰¹å¤„ç†ä»»åŠ¡ç®¡ç†

#### 7. é…ç½®ç®¡ç†åŠŸèƒ½

**FR-7.1 ç³»ç»Ÿé…ç½®**
- æ¨¡å‹å‚æ•°é…ç½®ï¼ˆé€šé“æ•°ã€å±‚æ•°ç­‰ï¼‰
- å›¾åƒå¤„ç†å‚æ•°é…ç½®
- è·¯å¾„é…ç½®ï¼ˆæ¨¡å‹æƒé‡ã€æ•°æ®ç›®å½•ç­‰ï¼‰

**FR-7.2 è¿è¡Œæ—¶é…ç½®**
- è®¾å¤‡é€‰æ‹©ï¼ˆCPU/GPUï¼‰
- æ‰¹å¤„ç†å¤§å°
- å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°

#### 8. éåŠŸèƒ½éœ€æ±‚

**NFR-1 æ€§èƒ½éœ€æ±‚**
- å•å¼ 256Ã—256å›¾åƒå¤„ç†æ—¶é—´ï¼šâ‰¤5ç§’ï¼ˆGPUï¼‰/ â‰¤15ç§’ï¼ˆCPUï¼‰
- æ‰¹é‡å¤„ç†æ”¯æŒï¼šâ‰¥10å¼ å›¾åƒ/åˆ†é’Ÿ
- å†…å­˜å ç”¨ï¼šâ‰¤4GBï¼ˆæ¨ç†æ¨¡å¼ï¼‰
- æ”¯æŒå¤šGPUå¹¶è¡Œå¤„ç†

**NFR-2 å¯é æ€§éœ€æ±‚**
- ç³»ç»Ÿå¯ç”¨æ€§ï¼šâ‰¥99%
- é”™è¯¯å¤„ç†ï¼šå®Œå–„çš„å¼‚å¸¸æ•è·å’Œæç¤º
- æ¨¡å‹é²æ£’æ€§ï¼šå¯¹ä¸åŒè´¨é‡å›¾åƒçš„é€‚åº”èƒ½åŠ›

**NFR-3 å¯ç”¨æ€§éœ€æ±‚**
- ç•Œé¢è¯­è¨€ï¼šæ”¯æŒä¸­è‹±æ–‡
- å­¦ä¹ æˆæœ¬ï¼šâ‰¤30åˆ†é’Ÿä¸Šæ‰‹
- æ–‡æ¡£å®Œæ•´æ€§ï¼šåŒ…å«å®‰è£…ã€ä½¿ç”¨ã€APIæ–‡æ¡£

**NFR-4 å¯ç»´æŠ¤æ€§éœ€æ±‚**
- ä»£ç è§„èŒƒï¼šéµå¾ªPEP8
- æ¨¡å—åŒ–è®¾è®¡ï¼šé«˜å†…èšä½è€¦åˆ
- æ—¥å¿—è®°å½•ï¼šå®Œæ•´çš„è¿è¡Œæ—¥å¿—
- å•å…ƒæµ‹è¯•è¦†ç›–ç‡ï¼šâ‰¥70%ï¼ˆå¯æ‰©å±•ï¼‰

**NFR-5 å®‰å…¨æ€§éœ€æ±‚**
- æ•°æ®åŠ å¯†ï¼šæ•æ„ŸåŒ»ç–—æ•°æ®ä¼ è¾“åŠ å¯†
- è®¿é—®æ§åˆ¶ï¼šç”¨æˆ·æƒé™ç®¡ç†ï¼ˆå¯æ‰©å±•ï¼‰
- å®¡è®¡æ—¥å¿—ï¼šæ“ä½œè®°å½•è¿½æº¯

---

## 5.2 ç³»ç»Ÿæ¶æ„è®¾è®¡

### 5.2.1 æ€»ä½“æ¶æ„

#### 1. ç³»ç»Ÿæ¶æ„æ¦‚è¿°

æœ¬ç³»ç»Ÿé‡‡ç”¨**ä¸‰å±‚æ¶æ„æ¨¡å¼**ï¼ŒåŒ…æ‹¬è¡¨ç¤ºå±‚ã€ä¸šåŠ¡é€»è¾‘å±‚å’Œæ•°æ®è®¿é—®å±‚ï¼Œç¡®ä¿ç³»ç»Ÿçš„å¯æ‰©å±•æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚ç³»ç»Ÿæ ¸å¿ƒé‡‡ç”¨**ä¸¤é˜¶æ®µåˆ†å‰²æµæ°´çº¿**è®¾è®¡ï¼Œç»“åˆæ·±åº¦å­¦ä¹ ç²—åˆ†å‰²å’Œæ‰©æ•£æ¨¡å‹ç²¾ç»†åŒ–æŠ€æœ¯ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          è¡¨ç¤ºå±‚ (Presentation Layer)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Webç•Œé¢(Gradio)  â”‚  â”‚   Python API     â”‚  â”‚ CLIå‘½ä»¤è¡Œå·¥å…·  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ä¸šåŠ¡é€»è¾‘å±‚ (Business Logic Layer)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                    â”‚ Segmentation Pipelineâ”‚                      â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                               â†“                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ å›¾åƒé¢„å¤„ç† â”‚â†’â”‚ CPUNetç²—åˆ†å‰² â”‚â†’â”‚ æ‰©æ•£ä¼˜åŒ–  â”‚â†’â”‚ ç»“æœåå¤„ç†    â”‚ â”‚
â”‚  â”‚ Module   â”‚  â”‚   Module    â”‚  â”‚ Module   â”‚  â”‚   Module     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚        â†‘                                              â†“          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ é…ç½®ç®¡ç†æ¨¡å—  â”‚                          â”‚  å¯è§†åŒ–æ¨¡å—      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ•°æ®è®¿é—®å±‚ (Data Access Layer)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ å›¾åƒæ•°æ®åŠ è½½  â”‚  â”‚ æ¨¡å‹æƒé‡ç®¡ç†  â”‚  â”‚  ç»“æœå­˜å‚¨ç®¡ç†       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 2. æ ¸å¿ƒå¤„ç†æµç¨‹

ç³»ç»Ÿçš„æ ¸å¿ƒå¤„ç†æµç¨‹å¦‚ä¸‹ï¼š

```
è¾“å…¥å›¾åƒ (Input Image)
    â†“
[1] å›¾åƒé¢„å¤„ç† (Preprocessing)
    â”œâ”€ æ ¼å¼è¯†åˆ«ä¸è§£ç  (DICOM/NIfTI/PNG/JPEG...)
    â”œâ”€ ç°åº¦åŒ–è½¬æ¢
    â”œâ”€ å¼ºåº¦å½’ä¸€åŒ– (MinMax/Z-score)
    â”œâ”€ å¯¹æ¯”åº¦å¢å¼º (CLAHE)
    â”œâ”€ é™å™ªå¤„ç† (Gaussian/Median)
    â””â”€ å°ºå¯¸è°ƒæ•´ (Resize to 256Ã—256)
    â†“
[2] CPUNetç²—åˆ†å‰² (Coarse Segmentation)
    â”œâ”€ Encoder: ç‰¹å¾æå– (4å±‚ä¸‹é‡‡æ ·: 64â†’128â†’256â†’512é€šé“)
    â”œâ”€ Bottleneck: æ·±å±‚ç‰¹å¾è¡¨ç¤º
    â”œâ”€ Attention Gates: æ³¨æ„åŠ›æœºåˆ¶å¼•å¯¼
    â”œâ”€ Decoder: ç‰¹å¾é‡å»º (4å±‚ä¸Šé‡‡æ · + Skip Connections)
    â””â”€ Output: ç²—åˆ†å‰²æ©ç  (æ¦‚ç‡å›¾)
    â†“
[3] æ‰©æ•£ä¼˜åŒ– (Diffusion Refinement) [å¯é€‰]
    â”œâ”€ å™ªå£°è°ƒåº¦: çº¿æ€§/ä½™å¼¦ Beta Schedule (1000æ­¥)
    â”œâ”€ æ¡ä»¶è¾“å…¥: åŸå§‹å›¾åƒ + ç²—åˆ†å‰²æ©ç 
    â”œâ”€ è¿­ä»£å»å™ª: Tæ­¥åå‘æ‰©æ•£è¿‡ç¨‹ (é»˜è®¤20æ­¥)
    â”œâ”€ U-Net Denoiser: æ—¶é—´æ­¥åµŒå…¥ + æ¡ä»¶ç¼–ç 
    â””â”€ Output: ç²¾ç»†åŒ–åˆ†å‰²æ©ç 
    â†“
[4] åå¤„ç† (Postprocessing)
    â”œâ”€ äºŒå€¼åŒ–: é˜ˆå€¼åˆ†å‰² (threshold=0.5)
    â”œâ”€ å½¢æ€å­¦æ“ä½œ: å¼€è¿ç®—/é—­è¿ç®—
    â”œâ”€ è¿é€šåŸŸåˆ†æ: å°å¯¹è±¡ç§»é™¤
    â”œâ”€ å­”æ´å¡«å……: Hole Filling
    â””â”€ è¾¹ç•Œå¹³æ»‘: Contour Smoothing
    â†“
[5] ç»“æœå¯è§†åŒ– (Visualization)
    â”œâ”€ æ©ç å åŠ : Overlay with adjustable alpha
    â”œâ”€ è½®å»“ç»˜åˆ¶: Contour drawing
    â”œâ”€ å¯¹æ¯”æ˜¾ç¤º: Before/After comparison
    â””â”€ ç»Ÿè®¡ä¿¡æ¯: Area, Percentage, Metrics
    â†“
è¾“å‡ºç»“æœ (Output Results)
```

#### 3. æŠ€æœ¯æ¶æ„æ ˆ

**æ·±åº¦å­¦ä¹ æ¡†æ¶**
- PyTorch 2.0+: æ ¸å¿ƒæ·±åº¦å­¦ä¹ æ¡†æ¶
- TorchVision: å›¾åƒå¤„ç†å’Œæ¨¡å‹å·¥å…·

**å›¾åƒå¤„ç†**
- NumPy: æ•°å€¼è®¡ç®—
- OpenCV: å›¾åƒå¤„ç†å’Œå¢å¼º
- Pillow (PIL): å›¾åƒI/O
- scikit-image: ç§‘å­¦å›¾åƒå¤„ç†
- SimpleITK: åŒ»å­¦å›¾åƒå¤„ç†
- pydicom: DICOMæ ¼å¼æ”¯æŒ

**ç”¨æˆ·ç•Œé¢**
- Gradio 4.0+: Webäº¤äº’ç•Œé¢
- Matplotlib: å›¾è¡¨ç»˜åˆ¶

**æ•°æ®å¢å¼º**
- Albumentations: é«˜æ€§èƒ½æ•°æ®å¢å¼ºåº“

**ç§‘å­¦è®¡ç®—**
- SciPy: ç§‘å­¦è®¡ç®—å·¥å…·
- tqdm: è¿›åº¦æ¡æ˜¾ç¤º

#### 4. éƒ¨ç½²æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           ç”¨æˆ·ç»ˆç«¯ (User Terminal)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Webæµè§ˆå™¨   â”‚      â”‚  Pythonå®¢æˆ·ç«¯     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP/HTTPS          â”‚ APIè°ƒç”¨
         â†“                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        åº”ç”¨æœåŠ¡å™¨ (Application Server)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Gradio Web Server (Port 7860)     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Segmentation Pipeline Service     â”‚    â”‚
â”‚  â”‚   â”œâ”€ é¢„å¤„ç†æœåŠ¡                      â”‚    â”‚
â”‚  â”‚   â”œâ”€ CPUNetæ¨ç†æœåŠ¡                  â”‚    â”‚
â”‚  â”‚   â”œâ”€ Diffusionæ¨ç†æœåŠ¡               â”‚    â”‚
â”‚  â”‚   â””â”€ åå¤„ç†æœåŠ¡                      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        è®¡ç®—èµ„æº (Compute Resources)          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ GPUåŠ é€Ÿ      â”‚    â”‚  CPUåå¤‡         â”‚   â”‚
â”‚  â”‚ (CUDA)       â”‚    â”‚  (å¤šçº¿ç¨‹)        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         å­˜å‚¨å±‚ (Storage Layer)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚æ¨¡å‹æƒé‡åº“ â”‚  â”‚ å›¾åƒæ•°æ®åº“  â”‚  â”‚ç»“æœç¼“å­˜ â”‚  â”‚
â”‚  â”‚checkpointsâ”‚  â”‚   data/    â”‚  â”‚outputs/ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 5. æ•°æ®æµè®¾è®¡

**è®­ç»ƒé˜¶æ®µæ•°æ®æµ**
```
åŸå§‹æ•°æ®é›†
    â†“
æ•°æ®åŠ è½½å™¨ (DataLoader)
    â†“
æ•°æ®å¢å¼º (Augmentation)
    â†“
æ‰¹æ¬¡ç”Ÿæˆ (Batch Generation)
    â†“
æ¨¡å‹è®­ç»ƒ (Model Training)
    â”œâ”€ å‰å‘ä¼ æ’­ (Forward Pass)
    â”œâ”€ æŸå¤±è®¡ç®— (Loss Calculation)
    â”œâ”€ åå‘ä¼ æ’­ (Backward Pass)
    â””â”€ å‚æ•°æ›´æ–° (Parameter Update)
    â†“
æ¨¡å‹éªŒè¯ (Validation)
    â†“
æ£€æŸ¥ç‚¹ä¿å­˜ (Checkpoint Saving)
```

**æ¨ç†é˜¶æ®µæ•°æ®æµ**
```
è¾“å…¥å›¾åƒ
    â†“
é¢„å¤„ç† â†’ å¼ é‡åŒ–
    â†“
æ¨¡å‹æ¨ç† (æ— æ¢¯åº¦)
    â†“
ç»“æœåå¤„ç†
    â†“
å¯è§†åŒ–/ä¿å­˜
```

### 5.2.2 æ ¸å¿ƒæ¨¡å—è®¾è®¡

#### 1. å›¾åƒé¢„å¤„ç†æ¨¡å— (Preprocessing Module)

**æ–‡ä»¶ä½ç½®**: `utils/preprocessing.py`

**ä¸»è¦åŠŸèƒ½**:
- å¤šæ ¼å¼å›¾åƒåŠ è½½ä¸è§£æ
- å›¾åƒæ ‡å‡†åŒ–ä¸å½’ä¸€åŒ–
- å¯¹æ¯”åº¦å¢å¼º
- é™å™ªå¤„ç†

**æ ¸å¿ƒç±»ä¸å‡½æ•°**:

```python
# å›¾åƒåŠ è½½å‡½æ•°
def load_image(image_path: str) -> np.ndarray:
    """
    åŠ è½½å„ç§æ ¼å¼çš„åŒ»å­¦å›¾åƒ
    æ”¯æŒ: DICOM, NIfTI, PNG, JPEG, TIFF, BMP
    """
    # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©åˆé€‚çš„åŠ è½½æ–¹æ³•
    # DICOM: ä½¿ç”¨pydicom
    # NIfTI: ä½¿ç”¨SimpleITK
    # å…¶ä»–: ä½¿ç”¨PIL/OpenCV

# å›¾åƒå½’ä¸€åŒ–å‡½æ•°
def normalize_image(
    image: np.ndarray, 
    method: str = "minmax"
) -> np.ndarray:
    """
    å›¾åƒå¼ºåº¦å½’ä¸€åŒ–
    method: "minmax" æˆ– "zscore"
    """

# å¯¹æ¯”åº¦å¢å¼ºå‡½æ•°
def enhance_contrast(
    image: np.ndarray,
    clip_limit: float = 2.0,
    tile_grid_size: tuple = (8, 8)
) -> np.ndarray:
    """
    ä½¿ç”¨CLAHEè¿›è¡Œè‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–
    """

# é™å™ªå‡½æ•°
def denoise_image(
    image: np.ndarray,
    method: str = "gaussian",
    **kwargs
) -> np.ndarray:
    """
    å›¾åƒé™å™ª
    method: "gaussian", "median", "bilateral"
    """

# å®Œæ•´é¢„å¤„ç†æµæ°´çº¿
def preprocess_image(
    image: Union[str, np.ndarray],
    target_size: tuple = (256, 256),
    normalize: bool = True,
    enhance: bool = True,
    denoise: bool = False
) -> np.ndarray:
    """
    å®Œæ•´çš„å›¾åƒé¢„å¤„ç†æµæ°´çº¿
    """
```

**è®¾è®¡è¦ç‚¹**:
- æ¨¡å—åŒ–è®¾è®¡ï¼Œæ¯ä¸ªå¤„ç†æ­¥éª¤ç‹¬ç«‹
- æ”¯æŒå‚æ•°åŒ–é…ç½®
- å¼‚å¸¸å¤„ç†æœºåˆ¶å®Œå–„
- æ”¯æŒæ‰¹é‡å¤„ç†

#### 2. CPUNetç²—åˆ†å‰²æ¨¡å— (CPUNet Module)

**æ–‡ä»¶ä½ç½®**: `models/cpunet.py`

**æ¶æ„è®¾è®¡**:

```
è¾“å…¥: 1Ã—256Ã—256 (å•é€šé“ç°åº¦å›¾)
    â†“
Encoder (ç¼–ç å™¨)
â”œâ”€ Conv Block 1: 1 â†’ 64, Size: 256Ã—256
â”‚  â”œâ”€ Conv2d(3Ã—3) + BatchNorm + ReLU
â”‚  â””â”€ Conv2d(3Ã—3) + BatchNorm + ReLU
â”œâ”€ MaxPool â†’ 128Ã—128
â”œâ”€ Conv Block 2: 64 â†’ 128, Size: 128Ã—128
â”œâ”€ MaxPool â†’ 64Ã—64
â”œâ”€ Conv Block 3: 128 â†’ 256, Size: 64Ã—64
â”œâ”€ MaxPool â†’ 32Ã—32
â””â”€ Conv Block 4: 256 â†’ 512, Size: 32Ã—32
    â†“
Bottleneck (ç“¶é¢ˆå±‚)
â””â”€ Conv Block 5: 512 â†’ 512, Size: 16Ã—16
    â†“
Decoder (è§£ç å™¨) + Attention Gates
â”œâ”€ UpConv 1: 512 â†’ 256, Size: 32Ã—32
â”‚  â”œâ”€ Attention Gate (guide from encoder)
â”‚  â”œâ”€ Skip Connection from Encoder Block 4
â”‚  â””â”€ Conv Block: 512 â†’ 256
â”œâ”€ UpConv 2: 256 â†’ 128, Size: 64Ã—64
â”‚  â”œâ”€ Attention Gate
â”‚  â”œâ”€ Skip Connection from Encoder Block 3
â”‚  â””â”€ Conv Block: 256 â†’ 128
â”œâ”€ UpConv 3: 128 â†’ 64, Size: 128Ã—128
â”‚  â”œâ”€ Attention Gate
â”‚  â”œâ”€ Skip Connection from Encoder Block 2
â”‚  â””â”€ Conv Block: 128 â†’ 64
â””â”€ UpConv 4: 64 â†’ 64, Size: 256Ã—256
   â”œâ”€ Attention Gate
   â”œâ”€ Skip Connection from Encoder Block 1
   â””â”€ Conv Block: 128 â†’ 64
    â†“
Output Layer
â””â”€ Conv2d(1Ã—1): 64 â†’ 1 + Sigmoid
    â†“
è¾“å‡º: 1Ã—256Ã—256 (åˆ†å‰²æ¦‚ç‡å›¾)
```

**æ ¸å¿ƒç±»å®šä¹‰**:

```python
class CPUNet(nn.Module):
    """
    CPUNet - Coarse Prediction U-Net
    åŸºäºU-Netçš„åŒ»å­¦å›¾åƒåˆ†å‰²ç½‘ç»œï¼ŒåŠ å…¥æ³¨æ„åŠ›æœºåˆ¶
    """
    def __init__(
        self,
        in_channels: int = 1,
        out_channels: int = 1,
        base_channels: int = 64,
        num_blocks: int = 4
    ):
        # ç¼–ç å™¨
        self.encoders = nn.ModuleList([...])
        # ç“¶é¢ˆå±‚
        self.bottleneck = ConvBlock(...)
        # æ³¨æ„åŠ›é—¨
        self.attention_gates = nn.ModuleList([...])
        # è§£ç å™¨
        self.decoders = nn.ModuleList([...])
        # è¾“å‡ºå±‚
        self.output = nn.Conv2d(...) + nn.Sigmoid()
    
    def forward(self, x):
        # ç¼–ç è·¯å¾„
        encoder_features = []
        for encoder in self.encoders:
            x = encoder(x)
            encoder_features.append(x)
            x = self.pool(x)
        
        # ç“¶é¢ˆå±‚
        x = self.bottleneck(x)
        
        # è§£ç è·¯å¾„
        for i, decoder in enumerate(self.decoders):
            x = self.upsample(x)
            # æ³¨æ„åŠ›é—¨æœºåˆ¶
            skip_connection = self.attention_gates[i](
                encoder_features[-(i+1)], x
            )
            x = torch.cat([x, skip_connection], dim=1)
            x = decoder(x)
        
        return self.output(x)
```

**æ³¨æ„åŠ›é—¨æœºåˆ¶**:

```python
class AttentionGate(nn.Module):
    """
    æ³¨æ„åŠ›é—¨: å¼ºåŒ–é‡è¦ç‰¹å¾ï¼ŒæŠ‘åˆ¶æ— å…³ç‰¹å¾
    """
    def __init__(self, F_g, F_l, F_int):
        self.W_g = nn.Conv2d(F_g, F_int, 1)  # é—¨æ§ä¿¡å·
        self.W_x = nn.Conv2d(F_l, F_int, 1)  # è¾“å…¥ä¿¡å·
        self.psi = nn.Conv2d(F_int, 1, 1)    # æ³¨æ„åŠ›ç³»æ•°
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, g, x):
        g1 = self.W_g(g)
        x1 = self.W_x(x)
        psi = self.relu(g1 + x1)
        psi = self.sigmoid(self.psi(psi))
        return x * psi  # ç‰¹å¾é‡æ ‡å®š
```

**è®­ç»ƒæŸå¤±å‡½æ•°**:
- ä¸»è¦æŸå¤±: Binary Cross-Entropy (BCE)
- è¾…åŠ©æŸå¤±: Dice Loss
- ç»„åˆæŸå¤±: BCE + Î» * Dice Loss (Î»=0.5)

#### 3. æ‰©æ•£ä¼˜åŒ–æ¨¡å— (Diffusion Refinement Module)

**æ–‡ä»¶ä½ç½®**: `models/diffusion.py`

**ç†è®ºåŸºç¡€**:

æ‰©æ•£æ¨¡å‹åŸºäºå»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹(DDPM)ï¼Œé€šè¿‡ä»¥ä¸‹ä¸¤ä¸ªè¿‡ç¨‹å®ç°åˆ†å‰²è¾¹ç•Œä¼˜åŒ–ï¼š

1. **å‰å‘æ‰©æ•£è¿‡ç¨‹** (è®­ç»ƒé˜¶æ®µ):
   ```
   q(x_t | x_{t-1}) = N(x_t; âˆš(1-Î²_t)Â·x_{t-1}, Î²_tÂ·I)
   ```
   é€æ­¥å‘çœŸå®åˆ†å‰²æ©ç æ·»åŠ é«˜æ–¯å™ªå£°

2. **åå‘å»å™ªè¿‡ç¨‹** (æ¨ç†é˜¶æ®µ):
   ```
   p_Î¸(x_{t-1} | x_t, c) = N(x_{t-1}; Î¼_Î¸(x_t, t, c), Î£_Î¸(x_t, t))
   ```
   ä»¥åŸå§‹å›¾åƒcä¸ºæ¡ä»¶ï¼Œé€æ­¥å»å™ªæ¢å¤æ¸…æ™°è¾¹ç•Œ

**æ¶æ„è®¾è®¡**:

```python
class DiffusionRefinement(nn.Module):
    """
    åŸºäºDDPMçš„åˆ†å‰²æ©ç ç»†åŒ–æ¨¡å‹
    """
    def __init__(
        self,
        num_timesteps: int = 1000,
        beta_start: float = 0.0001,
        beta_end: float = 0.02,
        channels: int = 64
    ):
        # å™ªå£°è°ƒåº¦
        self.register_buffer('betas', 
            self._linear_beta_schedule(beta_start, beta_end, num_timesteps)
        )
        self.register_buffer('alphas', 1.0 - self.betas)
        self.register_buffer('alphas_cumprod', 
            torch.cumprod(self.alphas, dim=0)
        )
        
        # å»å™ªU-Net
        self.denoiser = DenoisingUNet(
            in_channels=2,  # å™ªå£°æ©ç  + æ¡ä»¶å›¾åƒ
            out_channels=1, # é¢„æµ‹çš„å™ªå£°
            channels=channels,
            num_res_blocks=2
        )
        
        # æ—¶é—´æ­¥åµŒå…¥
        self.time_embedding = SinusoidalPositionEmbedding(channels)
    
    def forward(self, x, t, condition):
        """
        å‰å‘ä¼ æ’­ï¼ˆè®­ç»ƒï¼‰
        x: çœŸå®æ©ç 
        t: æ—¶é—´æ­¥
        condition: æ¡ä»¶å›¾åƒ
        """
        # æ·»åŠ å™ªå£°
        noise = torch.randn_like(x)
        x_noisy = self.q_sample(x, t, noise)
        
        # é¢„æµ‹å™ªå£°
        noise_pred = self.denoiser(
            torch.cat([x_noisy, condition], dim=1),
            self.time_embedding(t)
        )
        
        return noise_pred, noise
    
    @torch.no_grad()
    def sample(self, coarse_mask, condition, num_steps=20):
        """
        é‡‡æ ·è¿‡ç¨‹ï¼ˆæ¨ç†ï¼‰
        ä»ç²—åˆ†å‰²æ©ç å¼€å§‹ï¼Œé€æ­¥å»å™ªç»†åŒ–
        """
        x = coarse_mask
        timesteps = torch.linspace(
            self.num_timesteps-1, 0, num_steps
        ).long()
        
        for t in timesteps:
            # é¢„æµ‹å™ªå£°
            noise_pred = self.denoiser(
                torch.cat([x, condition], dim=1),
                self.time_embedding(t)
            )
            
            # DDPMå»å™ªå…¬å¼
            x = self._denoise_step(x, noise_pred, t)
        
        return torch.sigmoid(x)  # è¿”å›ç»†åŒ–åçš„æ©ç 
```

**å»å™ªU-Netç»“æ„**:

```
è¾“å…¥: 2é€šé“ (å™ªå£°æ©ç  + åŸå§‹å›¾åƒ) + æ—¶é—´æ­¥åµŒå…¥
    â†“
Encoder
â”œâ”€ ResBlock + Attention (64 channels)
â”œâ”€ Downsample â†’ 128 channels
â”œâ”€ ResBlock + Attention (128 channels)
â”œâ”€ Downsample â†’ 256 channels
â””â”€ ResBlock + Attention (256 channels)
    â†“
Middle
â”œâ”€ ResBlock + Self-Attention (256 channels)
â””â”€ ResBlock (256 channels)
    â†“
Decoder
â”œâ”€ Upsample + Skip â†’ 128 channels
â”œâ”€ ResBlock + Attention (128 channels)
â”œâ”€ Upsample + Skip â†’ 64 channels
â””â”€ ResBlock + Attention (64 channels)
    â†“
Output
â””â”€ Conv2d(1Ã—1): 64 â†’ 1 (é¢„æµ‹å™ªå£°)
```

**å…³é”®ç»„ä»¶**:

```python
class ResidualBlock(nn.Module):
    """æ®‹å·®å—: ä¿ƒè¿›æ¢¯åº¦æµåŠ¨"""
    def forward(self, x, time_emb):
        h = self.conv1(x)
        h = h + self.time_mlp(time_emb)  # æ—¶é—´æ­¥æ¡ä»¶
        h = self.conv2(h)
        return h + self.residual_conv(x)

class SelfAttention(nn.Module):
    """è‡ªæ³¨æ„åŠ›: æ•è·é•¿ç¨‹ä¾èµ–"""
    def forward(self, x):
        q = self.query(x)
        k = self.key(x)
        v = self.value(x)
        attention = softmax(q @ k.T / âˆšd_k)
        return attention @ v
```

**æ¨ç†ä¼˜åŒ–**:
- DDIMé‡‡æ ·: åŠ é€Ÿæ¨ç†ï¼Œ20æ­¥å³å¯è·å¾—é«˜è´¨é‡ç»“æœ
- æ¡ä»¶å¼•å¯¼: åˆ©ç”¨åŸå§‹å›¾åƒä¿¡æ¯ä¿æŒåˆ†å‰²ä¸€è‡´æ€§
- å™ªå£°è°ƒåº¦: çº¿æ€§æˆ–ä½™å¼¦scheduleï¼Œå¹³è¡¡ç»†èŠ‚å’Œé€Ÿåº¦

#### 4. åå¤„ç†æ¨¡å— (Postprocessing Module)

**æ–‡ä»¶ä½ç½®**: `utils/postprocessing.py`

**ä¸»è¦åŠŸèƒ½**:

```python
def postprocess_mask(
    mask: np.ndarray,
    min_area: int = 100,
    fill_holes: bool = True,
    smooth_boundary: bool = True
) -> np.ndarray:
    """
    åˆ†å‰²æ©ç åå¤„ç†æµæ°´çº¿
    """
    # 1. äºŒå€¼åŒ–
    binary_mask = (mask > 0.5).astype(np.uint8)
    
    # 2. å½¢æ€å­¦æ“ä½œ
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))
    # å¼€è¿ç®—ï¼šå»é™¤å°å™ªå£°
    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)
    # é—­è¿ç®—ï¼šå¡«å……å°å­”æ´
    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)
    
    # 3. è¿é€šåŸŸåˆ†æä¸å°å¯¹è±¡ç§»é™¤
    from skimage.measure import label, regionprops
    labeled = label(binary_mask)
    for region in regionprops(labeled):
        if region.area < min_area:
            binary_mask[labeled == region.label] = 0
    
    # 4. å­”æ´å¡«å……
    if fill_holes:
        from scipy.ndimage import binary_fill_holes
        binary_mask = binary_fill_holes(binary_mask)
    
    # 5. è¾¹ç•Œå¹³æ»‘
    if smooth_boundary:
        contours, _ = cv2.findContours(
            binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )
        epsilon = 0.01 * cv2.arcLength(contours[0], True)
        smoothed = cv2.approxPolyDP(contours[0], epsilon, True)
        binary_mask = np.zeros_like(binary_mask)
        cv2.drawContours(binary_mask, [smoothed], -1, 1, -1)
    
    return binary_mask
```

**è´¨é‡è¯„ä¼°**:

```python
def compute_metrics(pred_mask, true_mask):
    """
    è®¡ç®—åˆ†å‰²è´¨é‡æŒ‡æ ‡
    """
    # Diceç³»æ•°
    intersection = np.sum(pred_mask * true_mask)
    dice = 2 * intersection / (np.sum(pred_mask) + np.sum(true_mask))
    
    # IoU (JaccardæŒ‡æ•°)
    union = np.sum((pred_mask + true_mask) > 0)
    iou = intersection / union
    
    # ç²¾ç¡®ç‡å’Œå¬å›ç‡
    precision = intersection / np.sum(pred_mask)
    recall = intersection / np.sum(true_mask)
    
    return {
        'dice': dice,
        'iou': iou,
        'precision': precision,
        'recall': recall
    }
```

#### 5. å¯è§†åŒ–æ¨¡å— (Visualization Module)

**æ–‡ä»¶ä½ç½®**: `utils/visualization.py`

**æ ¸å¿ƒåŠŸèƒ½**:

```python
def create_overlay(
    image: np.ndarray,
    mask: np.ndarray,
    color: tuple = (0, 255, 0),
    alpha: float = 0.4
) -> np.ndarray:
    """
    åˆ›å»ºæ©ç å åŠ å¯è§†åŒ–
    """
    # è½¬æ¢ä¸ºRGB
    if image.ndim == 2:
        image_rgb = cv2.cvtColor(
            (image * 255).astype(np.uint8), 
            cv2.COLOR_GRAY2RGB
        )
    else:
        image_rgb = image.copy()
    
    # åˆ›å»ºå½©è‰²æ©ç 
    colored_mask = np.zeros_like(image_rgb)
    colored_mask[mask > 0] = color
    
    # Alphaæ··åˆ
    overlay = cv2.addWeighted(
        image_rgb, 1-alpha, 
        colored_mask, alpha, 
        0
    )
    
    return overlay

def draw_contour(
    image: np.ndarray,
    mask: np.ndarray,
    color: tuple = (255, 0, 0),
    thickness: int = 2
) -> np.ndarray:
    """
    ç»˜åˆ¶åˆ†å‰²è½®å»“
    """
    contours, _ = cv2.findContours(
        (mask > 0).astype(np.uint8),
        cv2.RETR_EXTERNAL,
        cv2.CHAIN_APPROX_SIMPLE
    )
    
    result = image.copy()
    if result.ndim == 2:
        result = cv2.cvtColor(
            (result * 255).astype(np.uint8),
            cv2.COLOR_GRAY2RGB
        )
    
    cv2.drawContours(result, contours, -1, color, thickness)
    return result

def visualize_results(
    original: np.ndarray,
    coarse_mask: np.ndarray,
    refined_mask: np.ndarray,
    save_path: Optional[str] = None
):
    """
    ç»¼åˆå¯è§†åŒ–ç»“æœå¯¹æ¯”
    """
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    
    # åŸå§‹å›¾åƒ
    axes[0, 0].imshow(original, cmap='gray')
    axes[0, 0].set_title('Original Image')
    
    # ç²—åˆ†å‰²
    axes[0, 1].imshow(coarse_mask, cmap='gray')
    axes[0, 1].set_title('Coarse Segmentation')
    
    # ç²¾ç»†åˆ†å‰²
    axes[0, 2].imshow(refined_mask, cmap='gray')
    axes[0, 2].set_title('Refined Segmentation')
    
    # ç²—åˆ†å‰²å åŠ 
    axes[1, 0].imshow(
        create_overlay(original, coarse_mask, (255, 165, 0))
    )
    axes[1, 0].set_title('Coarse Overlay')
    
    # ç²¾ç»†åˆ†å‰²å åŠ 
    axes[1, 1].imshow(
        create_overlay(original, refined_mask, (0, 255, 0))
    )
    axes[1, 1].set_title('Refined Overlay')
    
    # å¯¹æ¯”å›¾
    comparison = draw_contour(original, coarse_mask, (255, 165, 0))
    comparison = draw_contour(comparison, refined_mask, (0, 255, 0))
    axes[1, 2].imshow(comparison)
    axes[1, 2].set_title('Comparison (Orange: Coarse, Green: Refined)')
    
    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.show()
```

#### 6. åˆ†å‰²æµæ°´çº¿æ¨¡å— (Segmentation Pipeline)

**æ–‡ä»¶ä½ç½®**: `pipeline.py`

**æ ¸å¿ƒç±»è®¾è®¡**:

```python
class SegmentationPipeline:
    """
    å®Œæ•´çš„åŒ»å­¦å›¾åƒåˆ†å‰²æµæ°´çº¿
    æ•´åˆé¢„å¤„ç†ã€CPUNetã€æ‰©æ•£ä¼˜åŒ–ã€åå¤„ç†
    """
    
    def __init__(
        self,
        cpunet_weights: Optional[str] = None,
        diffusion_weights: Optional[str] = None,
        device: str = "auto",
        use_diffusion: bool = True,
        num_inference_steps: int = 20
    ):
        # è®¾å¤‡é€‰æ‹©
        if device == "auto":
            self.device = torch.device(
                "cuda" if torch.cuda.is_available() else "cpu"
            )
        else:
            self.device = torch.device(device)
        
        # åŠ è½½CPUNet
        self.cpunet = CPUNet(**MODEL_CONFIG["cpunet"])
        if cpunet_weights:
            self.cpunet.load_state_dict(
                torch.load(cpunet_weights, map_location=self.device)
            )
        self.cpunet.to(self.device)
        self.cpunet.eval()
        
        # åŠ è½½æ‰©æ•£æ¨¡å‹
        self.use_diffusion = use_diffusion
        if use_diffusion:
            self.diffusion = DiffusionRefinement(**MODEL_CONFIG["diffusion"])
            if diffusion_weights:
                self.diffusion.load_state_dict(
                    torch.load(diffusion_weights, map_location=self.device)
                )
            self.diffusion.to(self.device)
            self.diffusion.eval()
        
        self.num_inference_steps = num_inference_steps
    
    @torch.no_grad()
    def segment_image(
        self,
        image: Union[str, np.ndarray],
        return_intermediate: bool = False,
        postprocess: bool = True
    ) -> Union[np.ndarray, Dict]:
        """
        å¯¹å•å¼ å›¾åƒè¿›è¡Œåˆ†å‰²
        
        Args:
            image: è¾“å…¥å›¾åƒï¼ˆè·¯å¾„æˆ–NumPyæ•°ç»„ï¼‰
            return_intermediate: æ˜¯å¦è¿”å›ä¸­é—´ç»“æœ
            postprocess: æ˜¯å¦è¿›è¡Œåå¤„ç†
        
        Returns:
            åˆ†å‰²æ©ç æˆ–åŒ…å«ä¸­é—´ç»“æœçš„å­—å…¸
        """
        # 1. é¢„å¤„ç†
        if isinstance(image, str):
            image = load_image(image)
        
        original_size = image.shape[:2]
        image_preprocessed = preprocess_image(
            image,
            target_size=IMAGE_CONFIG["input_size"]
        )
        
        # è½¬æ¢ä¸ºå¼ é‡
        image_tensor = torch.from_numpy(image_preprocessed).float()
        image_tensor = image_tensor.unsqueeze(0).unsqueeze(0)  # [1, 1, H, W]
        image_tensor = image_tensor.to(self.device)
        
        # 2. CPUNetç²—åˆ†å‰²
        coarse_mask = self.cpunet(image_tensor)
        coarse_mask_np = coarse_mask.squeeze().cpu().numpy()
        
        # 3. æ‰©æ•£ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰
        if self.use_diffusion:
            refined_mask = self.diffusion.sample(
                coarse_mask,
                image_tensor,
                num_steps=self.num_inference_steps
            )
            refined_mask_np = refined_mask.squeeze().cpu().numpy()
        else:
            refined_mask_np = coarse_mask_np
        
        # 4. åå¤„ç†
        if postprocess:
            refined_mask_np = postprocess_mask(refined_mask_np)
        
        # 5. è°ƒæ•´å›åŸå§‹å°ºå¯¸
        from skimage.transform import resize
        final_mask = resize(
            refined_mask_np,
            original_size,
            order=0,  # æœ€è¿‘é‚»æ’å€¼ï¼Œä¿æŒäºŒå€¼æ€§
            preserve_range=True,
            anti_aliasing=False
        )
        
        if return_intermediate:
            return {
                'input': image,
                'coarse_mask': resize(coarse_mask_np, original_size, order=0),
                'refined_mask': final_mask,
                'original_size': original_size
            }
        
        return final_mask
    
    def segment_batch(
        self,
        images: List[Union[str, np.ndarray]],
        batch_size: int = 4,
        postprocess: bool = True
    ) -> List[np.ndarray]:
        """
        æ‰¹é‡å›¾åƒåˆ†å‰²
        """
        results = []
        for i in range(0, len(images), batch_size):
            batch = images[i:i+batch_size]
            for image in batch:
                mask = self.segment_image(image, postprocess=postprocess)
                results.append(mask)
        return results
    
    def visualize(
        self,
        image: Union[str, np.ndarray],
        save_path: Optional[str] = None
    ):
        """
        å¯è§†åŒ–åˆ†å‰²ç»“æœ
        """
        results = self.segment_image(
            image,
            return_intermediate=True,
            postprocess=True
        )
        
        visualize_results(
            results['input'],
            results['coarse_mask'],
            results['refined_mask'],
            save_path
        )
```

#### 7. Webç•Œé¢æ¨¡å— (Web Interface)

**æ–‡ä»¶ä½ç½®**: `app.py`

**ä¸»è¦åŠŸèƒ½**:
- åŸºäºGradioçš„äº¤äº’å¼Webç•Œé¢
- å•å¼ å›¾åƒåˆ†å‰²
- æ‰¹é‡å›¾åƒå¤„ç†
- å®æ—¶å‚æ•°è°ƒæ•´
- ç»“æœå¯è§†åŒ–å’Œä¸‹è½½

**ç•Œé¢å¸ƒå±€**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Medical Image Intelligent Segmentation System       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  Tab 1: ğŸ“· Single Image                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Upload Image      â”‚  â”‚  Coarse Result               â”‚   â”‚
â”‚  â”‚  [Drag & Drop]     â”‚  â”‚  [Preview]                   â”‚   â”‚
â”‚  â”‚                    â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚  â˜‘ Use Diffusion   â”‚  â”‚  Refined Result              â”‚   â”‚
â”‚  â”‚  Alpha: [====]     â”‚  â”‚  [Preview]                   â”‚   â”‚
â”‚  â”‚  [Segment]         â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  Comparison                  â”‚   â”‚
â”‚                          â”‚  [Orange vs Green]           â”‚   â”‚
â”‚                          â”‚  Statistics: ...             â”‚   â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â”‚  Tab 2: ğŸ“ Batch Processing                                  â”‚
â”‚  Tab 3: â„¹ï¸ About                                             â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 8. è®­ç»ƒæ¨¡å— (Training Module)

**æ–‡ä»¶ä½ç½®**: `train.py`

**è®­ç»ƒæµç¨‹**:

```python
def train_cpunet(
    model, 
    train_loader, 
    val_loader,
    epochs=100,
    lr=1e-4
):
    """CPUNetè®­ç»ƒæµç¨‹"""
    optimizer = optim.Adam(model.parameters(), lr=lr)
    criterion_bce = nn.BCELoss()
    criterion_dice = DiceLoss()
    
    best_val_loss = float('inf')
    
    for epoch in range(epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0
        for images, masks in tqdm(train_loader):
            images, masks = images.to(device), masks.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            
            # ç»„åˆæŸå¤±
            loss_bce = criterion_bce(outputs, masks)
            loss_dice = criterion_dice(outputs, masks)
            loss = loss_bce + 0.5 * loss_dice
            
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for images, masks in val_loader:
                images, masks = images.to(device), masks.to(device)
                outputs = model(images)
                loss = criterion_bce(outputs, masks) + \
                       0.5 * criterion_dice(outputs, masks)
                val_loss += loss.item()
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), 'checkpoints/cpunet_best.pth')
        
        print(f"Epoch {epoch+1}/{epochs}")
        print(f"Train Loss: {train_loss/len(train_loader):.4f}")
        print(f"Val Loss: {val_loss/len(val_loader):.4f}")

def train_diffusion(
    model,
    cpunet,
    train_loader,
    val_loader,
    epochs=100,
    lr=1e-4
):
    """æ‰©æ•£æ¨¡å‹è®­ç»ƒæµç¨‹"""
    optimizer = optim.Adam(model.parameters(), lr=lr)
    criterion = nn.MSELoss()  # å™ªå£°é¢„æµ‹æŸå¤±
    
    for epoch in range(epochs):
        model.train()
        cpunet.eval()
        
        train_loss = 0
        for images, masks in tqdm(train_loader):
            images, masks = images.to(device), masks.to(device)
            
            # è·å–CPUNetç²—åˆ†å‰²
            with torch.no_grad():
                coarse_masks = cpunet(images)
            
            # éšæœºæ—¶é—´æ­¥
            t = torch.randint(
                0, model.num_timesteps, 
                (images.size(0),), 
                device=device
            )
            
            # æ‰©æ•£æ¨¡å‹å‰å‘ä¼ æ’­
            noise_pred, noise = model(masks, t, images)
            loss = criterion(noise_pred, noise)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
        
        print(f"Epoch {epoch+1}/{epochs}")
        print(f"Train Loss: {train_loss/len(train_loader):.4f}")
```

### 5.2.3 ç¯å¢ƒé…ç½®

#### 1. ç³»ç»Ÿè¦æ±‚

**ç¡¬ä»¶è¦æ±‚**:

| ç»„ä»¶ | æœ€ä½é…ç½® | æ¨èé…ç½® |
|------|---------|---------|
| CPU | Intel i5 æˆ– AMD Ryzen 5 | Intel i7/i9 æˆ– AMD Ryzen 7/9 |
| å†…å­˜ | 8GB RAM | 16GB+ RAM |
| GPU | æ— ï¼ˆå¯ç”¨CPUè¿è¡Œï¼‰ | NVIDIA GPU 6GB+ VRAM (RTX 3060/T4åŠä»¥ä¸Š) |
| å­˜å‚¨ | 10GB å¯ç”¨ç©ºé—´ | 50GB+ SSD |
| æ“ä½œç³»ç»Ÿ | Linux / Windows / macOS | Ubuntu 20.04+ / Windows 10+ |

**è½¯ä»¶è¦æ±‚**:

| è½¯ä»¶ | ç‰ˆæœ¬è¦æ±‚ |
|------|---------|
| Python | 3.8 - 3.11 |
| CUDA (å¦‚ä½¿ç”¨GPU) | 11.7+ |
| cuDNN (å¦‚ä½¿ç”¨GPU) | 8.0+ |

#### 2. ä¾èµ–åŒ…åˆ—è¡¨

**æ ¸å¿ƒä¾èµ–** (`requirements.txt`):

```txt
# æ·±åº¦å­¦ä¹ æ¡†æ¶
torch>=2.0.0
torchvision>=0.15.0

# æ•°å€¼è®¡ç®—
numpy>=1.21.0
scipy>=1.7.0

# å›¾åƒå¤„ç†
Pillow>=9.0.0
opencv-python>=4.5.0
scikit-image>=0.19.0

# åŒ»å­¦å›¾åƒæ ¼å¼æ”¯æŒ
SimpleITK>=2.2.0
pydicom>=2.3.0

# Webç•Œé¢
gradio>=4.0.0

# æ•°æ®å¢å¼º
albumentations>=1.3.0

# å¯è§†åŒ–
matplotlib>=3.5.0

# å·¥å…·åº“
tqdm>=4.62.0
```

**å¯é€‰ä¾èµ–**:
```txt
# æ¨¡å‹åŠ é€Ÿ
onnxruntime-gpu>=1.12.0  # ONNXæ¨ç†åŠ é€Ÿ
tensorrt>=8.5.0           # TensorRTåŠ é€Ÿï¼ˆéœ€NVIDIA GPUï¼‰

# å¼€å‘å·¥å…·
pytest>=7.0.0             # å•å…ƒæµ‹è¯•
black>=22.0.0             # ä»£ç æ ¼å¼åŒ–
flake8>=4.0.0             # ä»£ç æ£€æŸ¥
jupyter>=1.0.0            # äº¤äº’å¼å¼€å‘
```

#### 3. å®‰è£…æ­¥éª¤

**æ­¥éª¤1: å…‹éš†ä»“åº“**

```bash
git clone https://github.com/TalosLong/Diffusinorefinement.git
cd Diffusinorefinement
```

**æ­¥éª¤2: åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**

```bash
# ä½¿ç”¨venvï¼ˆPythonè‡ªå¸¦ï¼‰
python -m venv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Linux/Mac:
source venv/bin/activate
# Windows:
.\venv\Scripts\activate

# æˆ–ä½¿ç”¨conda
conda create -n mediseg python=3.10
conda activate mediseg
```

**æ­¥éª¤3: å®‰è£…ä¾èµ–**

```bash
# å®‰è£…PyTorchï¼ˆæ ¹æ®CUDAç‰ˆæœ¬é€‰æ‹©ï¼‰
# CPUç‰ˆæœ¬:
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu

# CUDA 11.8ç‰ˆæœ¬:
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1ç‰ˆæœ¬:
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements.txt
```

**æ­¥éª¤4: éªŒè¯å®‰è£…**

```bash
# éªŒè¯PyTorchå®‰è£…
python -c "import torch; print(f'PyTorch version: {torch.__version__}')"
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"

# éªŒè¯å…¶ä»–åŒ…
python -c "import gradio; import cv2; import pydicom; print('All packages installed successfully!')"
```

#### 4. é…ç½®æ–‡ä»¶è¯´æ˜

**é…ç½®æ–‡ä»¶ä½ç½®**: `configs/config.py`

```python
# æ¨¡å‹é…ç½®
MODEL_CONFIG = {
    "cpunet": {
        "in_channels": 1,        # è¾“å…¥é€šé“æ•°ï¼ˆ1=ç°åº¦å›¾ï¼‰
        "out_channels": 1,       # è¾“å‡ºé€šé“æ•°ï¼ˆ1=äºŒå€¼åˆ†å‰²ï¼‰
        "base_channels": 64,     # åŸºç¡€ç‰¹å¾é€šé“æ•°
        "num_blocks": 4,         # ç¼–ç å™¨/è§£ç å™¨å—æ•°
    },
    "diffusion": {
        "num_timesteps": 1000,   # æ‰©æ•£æ€»æ­¥æ•°
        "beta_start": 0.0001,    # å™ªå£°è°ƒåº¦èµ·å§‹å€¼
        "beta_end": 0.02,        # å™ªå£°è°ƒåº¦ç»“æŸå€¼
        "channels": 64,          # U-Neté€šé“æ•°
        "num_res_blocks": 2,     # æ®‹å·®å—æ•°é‡
    }
}

# å›¾åƒé…ç½®
IMAGE_CONFIG = {
    "input_size": (256, 256),    # æ¨¡å‹è¾“å…¥å°ºå¯¸
    "normalize_mean": 0.5,       # å½’ä¸€åŒ–å‡å€¼
    "normalize_std": 0.5,        # å½’ä¸€åŒ–æ ‡å‡†å·®
}

# å¤„ç†é…ç½®
PROCESSING_CONFIG = {
    "batch_size": 1,             # æ‰¹å¤„ç†å¤§å°
    "device": "cuda",            # è®¡ç®—è®¾å¤‡ (cuda/cpu/auto)
    "num_workers": 4,            # æ•°æ®åŠ è½½çº¿ç¨‹æ•°
}

# è·¯å¾„é…ç½®
PATHS = {
    "models_dir": "./checkpoints",    # æ¨¡å‹æƒé‡ç›®å½•
    "data_dir": "./data",             # æ•°æ®ç›®å½•
    "output_dir": "./outputs",        # è¾“å‡ºç›®å½•
}

# æ”¯æŒçš„å›¾åƒæ ¼å¼
SUPPORTED_FORMATS = [
    ".png", ".jpg", ".jpeg",     # å¸¸è§æ ¼å¼
    ".bmp", ".tif", ".tiff",     # æ— æŸæ ¼å¼
    ".dcm",                      # DICOM
    ".nii", ".nii.gz"           # NIfTI
]
```

#### 5. ç›®å½•ç»“æ„

```
Diffusinorefinement/
â”œâ”€â”€ app.py                      # Webç•Œé¢ä¸»ç¨‹åº
â”œâ”€â”€ pipeline.py                 # åˆ†å‰²æµæ°´çº¿
â”œâ”€â”€ train.py                    # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ requirements.txt            # Pythonä¾èµ–
â”œâ”€â”€ README.md                   # è‹±æ–‡README
â”œâ”€â”€ é¡¹ç›®è¯´æ˜æ–‡æ¡£.md              # ä¸­æ–‡è¯´æ˜æ–‡æ¡£ï¼ˆæœ¬æ–‡æ¡£ï¼‰
â”œâ”€â”€ .gitignore                  # Gitå¿½ç•¥æ–‡ä»¶
â”‚
â”œâ”€â”€ configs/                    # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py               # ç³»ç»Ÿé…ç½®
â”‚
â”œâ”€â”€ models/                     # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cpunet.py               # CPUNetæ¨¡å‹
â”‚   â”œâ”€â”€ diffusion.py            # æ‰©æ•£æ¨¡å‹
â”‚   â””â”€â”€ ...                     # å…¶ä»–æ¨¡å‹æ–‡ä»¶
â”‚
â”œâ”€â”€ utils/                      # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py        # é¢„å¤„ç†å·¥å…·
â”‚   â”œâ”€â”€ postprocessing.py       # åå¤„ç†å·¥å…·
â”‚   â””â”€â”€ visualization.py        # å¯è§†åŒ–å·¥å…·
â”‚
â”œâ”€â”€ checkpoints/                # æ¨¡å‹æƒé‡ï¼ˆä¸åŒ…å«åœ¨ä»“åº“ä¸­ï¼‰
â”‚   â”œâ”€â”€ cpunet_best.pth
â”‚   â””â”€â”€ diffusion_best.pth
â”‚
â”œâ”€â”€ data/                       # è®­ç»ƒæ•°æ®ï¼ˆä¸åŒ…å«åœ¨ä»“åº“ä¸­ï¼‰
â”‚   â”œâ”€â”€ images/                 # åŸå§‹å›¾åƒ
â”‚   â””â”€â”€ masks/                  # åˆ†å‰²æ ‡æ³¨
â”‚
â”œâ”€â”€ outputs/                    # è¾“å‡ºç»“æœ
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ tests/                      # å•å…ƒæµ‹è¯•ï¼ˆå¯é€‰ï¼‰
    â””â”€â”€ ...
```

#### 6. å¿«é€Ÿå¯åŠ¨æŒ‡å—

**æ–¹å¼1: Webç•Œé¢**

```bash
# å¯åŠ¨Gradio Webç•Œé¢
python app.py

# æµè§ˆå™¨è®¿é—®
# http://localhost:7860
```

**æ–¹å¼2: Python API**

```python
from pipeline import SegmentationPipeline

# åˆ›å»ºæµæ°´çº¿å®ä¾‹
pipeline = SegmentationPipeline(
    cpunet_weights="checkpoints/cpunet_best.pth",      # å¯é€‰
    diffusion_weights="checkpoints/diffusion_best.pth", # å¯é€‰
    device="auto",           # è‡ªåŠ¨é€‰æ‹©GPU/CPU
    use_diffusion=True,      # å¯ç”¨æ‰©æ•£ä¼˜åŒ–
)

# å•å¼ å›¾åƒåˆ†å‰²
mask = pipeline.segment_image("path/to/image.png")

# å¸¦ä¸­é—´ç»“æœ
results = pipeline.segment_image(
    "path/to/image.png",
    return_intermediate=True
)

# æ‰¹é‡å¤„ç†
masks = pipeline.segment_batch([
    "image1.png",
    "image2.png",
    "image3.png"
])

# å¯è§†åŒ–
pipeline.visualize("path/to/image.png", save_path="result.png")
```

**æ–¹å¼3: å‘½ä»¤è¡Œè®­ç»ƒ**

```bash
# è®­ç»ƒCPUNet
python train.py \
    --model cpunet \
    --data_dir ./data \
    --output_dir ./checkpoints \
    --epochs 100 \
    --batch_size 8 \
    --lr 1e-4

# è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼ˆéœ€è¦é¢„è®­ç»ƒçš„CPUNetï¼‰
python train.py \
    --model diffusion \
    --data_dir ./data \
    --cpunet_weights ./checkpoints/cpunet_best.pth \
    --epochs 100 \
    --batch_size 4 \
    --lr 1e-4

# è”åˆè®­ç»ƒ
python train.py \
    --model both \
    --data_dir ./data \
    --epochs 100
```

#### 7. å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

**Q1: CUDA out of memoryé”™è¯¯**

è§£å†³æ–¹æ¡ˆ:
```python
# å‡å°æ‰¹å¤„ç†å¤§å°
PROCESSING_CONFIG["batch_size"] = 1

# å‡å°‘æ‰©æ•£æ¨ç†æ­¥æ•°
pipeline = SegmentationPipeline(num_inference_steps=10)

# ä½¿ç”¨CPUæ¨¡å¼
pipeline = SegmentationPipeline(device="cpu")
```

**Q2: å›¾åƒæ ¼å¼ä¸æ”¯æŒ**

è§£å†³æ–¹æ¡ˆ:
```python
# æ‰‹åŠ¨è½¬æ¢å›¾åƒæ ¼å¼
from PIL import Image
img = Image.open("unsupported.xyz")
img.save("converted.png")

# æˆ–ä½¿ç”¨ImageMagick
# convert unsupported.xyz converted.png
```

**Q3: Webç•Œé¢æ— æ³•è®¿é—®**

è§£å†³æ–¹æ¡ˆ:
```python
# æ£€æŸ¥ç«¯å£å ç”¨
# Linux/Mac: lsof -i :7860
# Windows: netstat -ano | findstr :7860

# æ›´æ”¹ç«¯å£
demo.launch(server_port=8080)

# å…è®¸å¤–ç½‘è®¿é—®
demo.launch(server_name="0.0.0.0", share=True)
```

**Q4: åˆ†å‰²æ•ˆæœä¸ä½³**

è°ƒä¼˜å»ºè®®:
- å¯ç”¨æ‰©æ•£ä¼˜åŒ–: `use_diffusion=True`
- å¢åŠ æ‰©æ•£æ­¥æ•°: `num_inference_steps=50`
- è°ƒæ•´åå¤„ç†å‚æ•°
- ä½¿ç”¨æ›´é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®é‡æ–°è®­ç»ƒæ¨¡å‹

#### 8. æ€§èƒ½ä¼˜åŒ–å»ºè®®

**æ¨ç†åŠ é€Ÿ**:
- ä½¿ç”¨GPU: æ¯”CPUå¿«10-50å€
- å¯ç”¨æ··åˆç²¾åº¦: `torch.cuda.amp`
- æ¨¡å‹é‡åŒ–: è½¬æ¢ä¸ºINT8
- ONNXå¯¼å‡º: ä½¿ç”¨ONNX RuntimeåŠ é€Ÿ
- TensorRTä¼˜åŒ–: NVIDIA GPUæœ€ä½³æ€§èƒ½

**å†…å­˜ä¼˜åŒ–**:
- å‡å°æ‰¹å¤„ç†å¤§å°
- ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆè®­ç»ƒæ—¶ï¼‰
- æ¸…ç†ä¸­é—´å˜é‡: `del tensor; torch.cuda.empty_cache()`

**å¹¶è¡Œå¤„ç†**:
- å¤šGPUè®­ç»ƒ: `torch.nn.DataParallel`
- åˆ†å¸ƒå¼è®­ç»ƒ: `torch.distributed`
- CPUå¤šçº¿ç¨‹: å¢åŠ `num_workers`

---

## é™„å½•

### A. æŠ€æœ¯å‚è€ƒæ–‡çŒ®

1. **U-Net**: Ronneberger, O., Fischer, P., & Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation. MICCAI.

2. **Attention U-Net**: Oktay, O., et al. (2018). Attention U-Net: Learning Where to Look for the Pancreas. MIDL.

3. **DDPM**: Ho, J., Jain, A., & Abbeel, P. (2020). Denoising Diffusion Probabilistic Models. NeurIPS.

4. **Diffusion Models for Medical Imaging**: Wolleb, J., et al. (2022). Diffusion Models for Medical Anomaly Detection. MICCAI.

### B. æœ¯è¯­è¡¨

| æœ¯è¯­ | è‹±æ–‡ | è¯´æ˜ |
|------|------|------|
| åŒ»å­¦å›¾åƒåˆ†å‰² | Medical Image Segmentation | ä»åŒ»å­¦å½±åƒä¸­æå–æ„Ÿå…´è¶£åŒºåŸŸ |
| æ‰©æ•£æ¨¡å‹ | Diffusion Model | åŸºäºå»å™ªçš„ç”Ÿæˆæ¨¡å‹ |
| U-Net | U-Net | Uå‹ç¼–ç å™¨-è§£ç å™¨æ¶æ„ |
| æ³¨æ„åŠ›æœºåˆ¶ | Attention Mechanism | é€‰æ‹©æ€§èšç„¦é‡è¦ç‰¹å¾ |
| DDPM | Denoising Diffusion Probabilistic Model | å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ |
| CLAHE | Contrast Limited Adaptive Histogram Equalization | å¯¹æ¯”åº¦å—é™è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ– |
| Diceç³»æ•° | Dice Coefficient | åˆ†å‰²ç›¸ä¼¼åº¦åº¦é‡ |
| IoU | Intersection over Union | äº¤å¹¶æ¯” |

### C. è”ç³»æ–¹å¼

- **é¡¹ç›®ä»“åº“**: https://github.com/TalosLong/Diffusinorefinement
- **é—®é¢˜åé¦ˆ**: é€šè¿‡GitHub Issuesæäº¤
- **é‚®ä»¶è”ç³»**: [é¡¹ç›®è´Ÿè´£äººé‚®ç®±]

### D. ç‰ˆæƒä¸è®¸å¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯å¼€æºã€‚è¯¦è§LICENSEæ–‡ä»¶ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2026-02-21
**ä½œè€…**: Diffusinorefinementå¼€å‘å›¢é˜Ÿ
